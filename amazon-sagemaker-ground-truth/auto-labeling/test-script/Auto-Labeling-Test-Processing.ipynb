{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dd7e7c",
   "metadata": {},
   "source": [
    "# Semantic Segmentation 自動ラベリング検証\n",
    "\n",
    "このノートブックは、ラベリング済みのデータセットを使って自動ラベリングによってどの程度工数が削減できるかを検証するためのサンプルノートブックです。検証手順は以下の通りです。\n",
    "\n",
    "1. Amazon SageMaker のビルトインアルゴリズムを使って、用意したラベルありデータセットから任意の数を取り出しモデルの学習を実施\n",
    "1. 作成したモデルを使って、残りのデータ（未ラベリングデータ扱い）に対して推論を行う（自動ラベリングに相当）\n",
    "1. 自動ラベリングの結果、評価値が閾値より高ければラベル済みデータとして扱う\n",
    "1. 自動ラベリングの結果、評価値が閾値より高いデータをラベリング済みデータリストに追加。このとき自動ラベリングで作成したラベル画像をモデルの学習に使用するよう変更（あらかじめ用意したラベル画像と差し替える）\n",
    "1. 評価値が高いデータの数が少なければ、未ラベリングデータの中から不足分だけ未ラベリングリストからラベリング済みリストに追加（手動ラベリング相当の処理）\n",
    "1. 自動ラベリングの結果、評価値が低いものは未ラベリングリストに戻す\n",
    "1. 増えたラベリング済みデータセットを使ってモデルを学習\n",
    "1. 以降、未ラベリングのデータがなくなるまで繰り返す\n",
    "\n",
    "Amazon SageMaker の Semantic Segmentation の詳細の使い方については [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/semantic-segmentation.html#semantic-segmentation-inputoutput) をご参照ください。\n",
    "\n",
    "## Amazon SageMaker のセットアップ\n",
    "\n",
    "以下のセルの `bucket` にデータを保存したいバケット名を記載してから実行してください。何も変更しない場合は Amazon SageMaker のデフォルトバケットが使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import numpy as np\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.s3 import parse_s3_url\n",
    "\n",
    "JST = tz.gettz('Asia/Tokyo')\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "ecr_client = boto3.client('ecr', region_name=region)\n",
    "\n",
    "prefix = 'auto-labeling-test'\n",
    "project_name = 'pascal-dataset'\n",
    "sagemaker_policy_name = project_name + '-cloudfront-waf-policy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1eb20",
   "metadata": {},
   "source": [
    "## データセットの準備\n",
    "[Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) を使用します。 データセットの詳細は [Pascal VOC Dataset page](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html)をご参照ください。分類クラスは以下の通りです。\n",
    "\n",
    "| Label Id |     Class     |\n",
    "|:--------:|:-------------:|\n",
    "|     0    |   Background  |\n",
    "|     1    |   Aeroplane   |\n",
    "|     2    |    Bicycle    |\n",
    "|     3    |      Bird     |\n",
    "|     4    |      Boat     |\n",
    "|    5     |     Bottle    |\n",
    "|     6    |      Bus      |\n",
    "|     7    |      Car      |\n",
    "|     8    |      Cat      |\n",
    "|     9    |     Chair     |\n",
    "|    10    |      Cow      |\n",
    "|    11    |  Dining Table |\n",
    "|    12    |      Dog      |\n",
    "|    13    |     Horse     |\n",
    "|    14    |   Motorbike   |\n",
    "|    15    |     Person    |\n",
    "|    16    |  Potted Plant |\n",
    "|    17    |     Sheep     |\n",
    "|    18    |      Sofa     |\n",
    "|    19    |     Train     |\n",
    "|    20    |  TV / Monitor |\n",
    "|    255   | Hole / Ignore |\n",
    "\n",
    "入力画像とラベル画像をそれぞれ data/image と data/annotation に保存し、Amazon S3 にアップロードします。また、SageMaker 学習ジョブの入力として使用するため、入力画像とラベル画像の対応を記載した manifest ファイルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Downloading the dataset...\")\n",
    "!wget -P /tmp https://fast-ai-imagelocal.s3.amazonaws.com/pascal-voc.tgz\n",
    "# S3 cp may be even faster on environments where it's available:\n",
    "# !aws s3 cp s3://fast-ai-imagelocal/pascal-voc.tgz /tmp/pascal-voc.tgz\n",
    "\n",
    "print(\"Extracting VOC2012...\")\n",
    "!tar -xf /tmp/pascal-voc.tgz --wildcards pascal-voc/VOC2012*\n",
    "\n",
    "print(\"Deleting /tmp files...\")\n",
    "!rm /tmp/pascal-voc.tgz\n",
    "\n",
    "# Alternatively could consider using the Oxford Uni source:\n",
    "#!wget -P /tmp http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "#!tar -xf /tmp/VOCtrainval_11-May-2012.tar -C pascal-voc/VOC2012\n",
    "#!rm /tmp/VOCtrainval_11-May-2012.tar\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ec219",
   "metadata": {},
   "source": [
    "以下のセルでは、画像を data フォルダ以下に集約しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directory structure mimicing the s3 bucket where data is to be dumped.\n",
    "VOC2012 = \"pascal-voc/VOC2012\"\n",
    "os.makedirs(\"data/image\", exist_ok=True)\n",
    "os.makedirs(\"data/annotation\", exist_ok=True)\n",
    "\n",
    "# Create a list of all validation images.\n",
    "# 画像1450枚くらい\n",
    "with open(VOC2012 + \"/ImageSets/Segmentation/val.txt\") as f:\n",
    "    val_list = f.read().splitlines()\n",
    "\n",
    "# Move the jpg images in validation list to validation directory and png images to validation_annotation directory.\n",
    "for i in val_list:\n",
    "    shutil.copy2(VOC2012 + \"/JPEGImages/\" + i + \".jpg\", \"data/image/\")\n",
    "    shutil.copy2(VOC2012 + \"/SegmentationClass/\" + i + \".png\", \"data/annotation/\")\n",
    "    \n",
    "# すべてのデータセットを使用するには以下をコメントアウトを解除してからこのセルを実行する\n",
    "# # Create a list of all validation images.\n",
    "# with open(VOC2012 + \"/ImageSets/Segmentation/train.txt\") as f:\n",
    "#     val_list = f.read().splitlines()\n",
    "\n",
    "# # Move the jpg images in validation list to validation directory and png images to validation_annotation directory.\n",
    "# for i in val_list:\n",
    "#     shutil.copy2(VOC2012 + \"/JPEGImages/\" + i + \".jpg\", \"data/image/\")\n",
    "#     shutil.copy2(VOC2012 + \"/SegmentationClass/\" + i + \".png\", \"data/annotation/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139a469",
   "metadata": {},
   "source": [
    "以下のセルでは、manifest ファイルを作成しています。100MB ほどの画像データを S3 にアップロードするため実行が完了するまでに少し時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd701cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "gt_job_name = 'semaseg'\n",
    "train_manifest_filename = 'train.manifest'\n",
    "train_file_list = glob.glob('data/image/*.jpg')\n",
    "num_training_samples = len(train_file_list)\n",
    "\n",
    "train_annotation_channel = sess.upload_data(\n",
    "    path=\"data\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=os.path.join(prefix, \"train-data\"),\n",
    ")\n",
    "\n",
    "with open(train_manifest_filename, 'w') as f:\n",
    "    for file in train_file_list:\n",
    "        file = os.path.basename(file)\n",
    "        train_data_path = os.path.join(train_annotation_channel, 'image', file)\n",
    "        train_annot_data_path = os.path.join(train_annotation_channel, 'annotation', file[:-3] + 'png')\n",
    "        manifest_format = '{\"source-ref\":\"' + train_data_path + '\",\"' + gt_job_name + '-ref\":\"'+ train_annot_data_path +'\",\"'+ gt_job_name +'-ref-metadata\":{\"job-name\":\"'+ gt_job_name +'\"}}'\n",
    "        f.write(manifest_format + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318e540",
   "metadata": {},
   "source": [
    "## [Optional] Amazon CloudFront と AWS WAF の準備\n",
    "\n",
    "この手順は、Amazon S3 に保存された PNG 画像を手軽に閲覧するためのしくみを構築するためのものです。そのため、別途画像をローカル環境にダウンロードして確認するので問題ないなど S3 バケットの画像をブラウザで直接確認する必要がなければここはスキップして次の「スクリプト実行用コンテナイメージ作成」に進んでください。\n",
    "\n",
    "Amazon S3 に保存された自動ラベリング画像を簡単に確認するために、Amazon CloudFront を使用します。また、ファイアウォールサービスである AWS WAF も併せて使用します。基本的にここの手順は一度のみ実行すれば OK です。データを保存するバケット、`project_name`、`prefix` を変更した場合は再度実行してください。使用しなくなったリソースはこのノートブックの一番下にあるリソース削除の手順を実施して削除してください。\n",
    "\n",
    "### IAM ポリシーの作成とノートブックインスタンスの IAM ロールへのアタッチ\n",
    "以下の手順で、Amazon CloudFront と AWS WAF を使用するための権限を持つ IAM ポリシーを作成し、ノートブックインスタンスの IAM ロールにアタッチしてください。\n",
    "\n",
    "まずは、IAM ポリシーの JSON ファイルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0100fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_name = 'sagemaker-policy.json'\n",
    "policy_json = f\"\"\"{{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {{\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"cloudfront:CreateDistribution\",\n",
    "                \"cloudfront:CreateCloudFrontOriginAccessIdentity\",\n",
    "                \"cloudfront:DeleteDistribution\",\n",
    "                \"cloudfront:UpdateDistribution\",\n",
    "                \"cloudfront:GetDistribution\",\n",
    "                \"cloudfront:DeleteCloudFrontOriginAccessIdentity\",\n",
    "                \"cloudfront:GetCloudFrontOriginAccessIdentity\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }},\n",
    "        {{\n",
    "            \"Sid\": \"VisualEditor1\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"wafv2:GetWebACL\",\n",
    "                \"wafv2:CreateWebACL\",\n",
    "                \"wafv2:DeleteWebACL\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:wafv2:*:{account_id}:*/webacl/*/*\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "with open(policy_name, 'w') as f:\n",
    "    f.write(policy_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c55e1",
   "metadata": {},
   "source": [
    "以下のセルを実行して表示された手順に従って IAM ポリシーを作成し、ノートブックインスタンスの IAM ロールにアタッチしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "text = f\"\"\"\n",
    "＜手順＞\n",
    "1. <a href=\\\"{policy_name}\\\" target=\\\"_blank\\\">{policy_name}</a> の中身をコピー\n",
    "1. <a href=\\\"https://{region}.console.aws.amazon.com/iam/home#/policies$new?step=edit\\\" target=\\\"_blank\\\">IAM Policy の作成</a>をクリックして **JSON** タブをクリックしてコピーした JSON をペーストして右下の **次のステップ：タグ** ボタンをクリック\n",
    "1. 右下の **次のステップ：確認** ボタンをクリック\n",
    "1. **名前** に **{sagemaker_policy_name}** を記載して、右下の **ポリシーの作成** ボタンをクリック\n",
    "1.  <a href=\\\"https://us-east-1.console.aws.amazon.com/sagemaker/home?region={region}#/notebook-instances\\\" target=\\\"_blank\\\">ノートブックインスタンス一覧</a> を開いてこのノートブックを実行しているノートブックをクリック\n",
    "1. **アクセス許可と暗号化** の部分に表示されている IAM ロールへのリンクをクリック\n",
    "1. **アクセス許可を追加** をクリックして **ポリシーをアタッチ** を選択\n",
    "1. **その他の許可ポリシー** の検索ボックスで手順4 で作成した {sagemaker_policy_name} を検索して横にあるチェックボックスをオンにする\n",
    "1. **ポリシーのアタッチ** をクリック\n",
    "\"\"\"\n",
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57718f",
   "metadata": {},
   "source": [
    "### Web ACL の作成\n",
    "\n",
    "以下のセルを実行して、Web ACL (Access Control List) を作成します。Web ACL を利用することで、保護されたリソース（今回は Amazon CloudFront）が応答するすべての HTTP (S) ウェブリクエストをきめ細かく制御できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waf2_client = boto3.client('wafv2')\n",
    "cloudfront_client = boto3.client('cloudfront')\n",
    "waf2_client_us = boto3.client('wafv2', region_name='us-east-1') # どのリージョンを使っていてもここは us-east-1 のままにする\n",
    "\n",
    "response = waf2_client_us.create_web_acl(\n",
    "    Name=prefix,\n",
    "    Scope='CLOUDFRONT',\n",
    "    DefaultAction={\n",
    "        'Allow': {},\n",
    "    },\n",
    "    VisibilityConfig={\n",
    "        'SampledRequestsEnabled': True,\n",
    "        'CloudWatchMetricsEnabled': False,\n",
    "        'MetricName': 'All'\n",
    "    },\n",
    ")\n",
    "acl_arn = response['Summary']['ARN']\n",
    "acl_name = response['Summary']['Name']\n",
    "acl_id = response['Summary']['Id']\n",
    "acl_lock_token = response['Summary']['LockToken']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8f044",
   "metadata": {},
   "source": [
    "### CloudFront Distribution の作成\n",
    "\n",
    "以下のセルを実行して、S3 バケットをオリジンとする CloudFront distribution を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "response = cloudfront_client.create_cloud_front_origin_access_identity(\n",
    "    CloudFrontOriginAccessIdentityConfig={\n",
    "        'CallerReference': timestamp,\n",
    "        'Comment': f'access-identity-{bucket}.s3.{region}.amazonaws.com'\n",
    "    }\n",
    ")\n",
    "oai_id = response['CloudFrontOriginAccessIdentity']['Id']\n",
    "\n",
    "response = cloudfront_client.create_distribution(\n",
    "    DistributionConfig={\n",
    "        'CallerReference': timestamp,\n",
    "        'Origins': {\n",
    "            'Quantity': 1,\n",
    "            'Items': [\n",
    "                {\n",
    "                    'Id': timestamp,\n",
    "                    'DomainName': f'{bucket}.s3.{region}.amazonaws.com',\n",
    "                    'OriginPath': f'/{prefix}/{project_name}',\n",
    "                    'S3OriginConfig': {\n",
    "                        'OriginAccessIdentity': f'origin-access-identity/cloudfront/{oai_id}'\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'DefaultCacheBehavior': {\n",
    "            'TargetOriginId': timestamp,\n",
    "            'ViewerProtocolPolicy': 'allow-all',\n",
    "            'CachePolicyId': '658327ea-f89d-4fab-a63d-7e88639e58f6',\n",
    "            'Compress': True,\n",
    "        },\n",
    "        'Comment': '',\n",
    "        'Enabled': True,\n",
    "        'WebACLId': acl_arn,\n",
    "    }\n",
    ")\n",
    "cloudfront_domain_name = response['Distribution']['DomainName']\n",
    "cloudfront_id = response['Distribution']['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4ba7d",
   "metadata": {},
   "source": [
    "### S3 バケットポリシーの設定\n",
    "\n",
    "データが保存されている Amazon S3 バケットのバケットポリシーに以下のセルを実行して表示されるテキストを追記してください。設定内容の詳細は [こちらのドキュメント](https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html#private-content-granting-permissions-to-oai) に記載されています。\n",
    "\n",
    "バケットポリシーの設定方法は以下の通りです。\n",
    "\n",
    "1. Amazon S3 のコンソールでバケット名をクリック\n",
    "1. [アクセス許可]タブをクリックし、[バケットポリシー]の部分にある[編集]ボタンをクリック\n",
    "1. 以下のセルを実行して表示されるテキストを \"Statement\" の中に追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = f\"\"\"{{\n",
    "    \\\"Sid\\\": \\\"{project_name}\\\",\n",
    "    \\\"Effect\\\": \\\"Allow\\\",\n",
    "    \\\"Principal\\\": {{\n",
    "        \\\"AWS\\\": \\\"arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity {oai_id}\\\"\n",
    "    }},\n",
    "    \\\"Action\\\": \\\"s3:GetObject\\\",\n",
    "    \\\"Resource\\\": \\\"arn:aws:s3:::{bucket}/*\\\"\n",
    "}}\n",
    "\"\"\"\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc371f0b",
   "metadata": {},
   "source": [
    "## スクリプト実行用コンテナイメージ作成\n",
    "\n",
    "検証用スクリプトの実行は、実行時間が長時間になることを想定してノートブックインスタンス上ではなく、Amazon SageMaker Processing を使って実現します。スクリプトが動作する環境のコンテナイメージを作成し、Amazon ECR に push します。\n",
    "\n",
    "ECR にコンテナイメージをプッシュする権限を得るために、ノートブックインスタンスにアタッチしている IAM role に、`AmazonEC2ContainerRegistryPowerUser` policy を追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34176124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile docker/requirements.txt\n",
    "\n",
    "boto3==1.20.30\n",
    "mxnet==1.8.0\n",
    "numpy==1.18.5\n",
    "pillow==9.0.0\n",
    "sagemaker==2.72.2\n",
    "scikit-learn==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join( 'docker/Dockerfile')\n",
    "\n",
    "build_config={f\"\"\"FROM python:3.7-slim-buster\n",
    "    \n",
    "ENV AWS_DEFAULT_REGION={region}\n",
    "\n",
    "RUN apt update \\\n",
    "  && apt install -y libopenblas-dev libgomp1 \\\n",
    "  && apt-get clean \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "COPY requirements.txt .\n",
    "RUN pip3 install -r requirements.txt\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "with open(filepath, 'w') as f:\n",
    "    f.write('\\n'.join(list(build_config)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60256c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = ':latest'\n",
    "ecr_repository = 'sagemaker-' + prefix\n",
    "image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{ecr_repository+tag}'\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t $ecr_repository docker\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print(f'Image has been pushed to {image_uri}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80689e1b",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Processing でスクリプト実行\n",
    "\n",
    "検証スクリプト `auto-labeling-test.py` を SageMaker Processing で実行します。このノートブックと同じパスに `auto-labeling-test.py` がある想定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02195d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_input_dir = '/opt/ml/processing/input'\n",
    "processing_output_dir = '/opt/ml/processing/output'\n",
    "job_name = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "EVALUATION_SCRIPT_LOCATION = \"auto-labeling-test.py\"\n",
    "SAMPLE_PNG_LOCATION = 'pascal-voc/VOC2012/SegmentationClass/2008_003701.png'\n",
    "MANIFEST_LOCATION = train_manifest_filename\n",
    "\n",
    "sample_label_png = sess.upload_data(\n",
    "    SAMPLE_PNG_LOCATION,\n",
    "    bucket=bucket,\n",
    "    key_prefix=os.path.join(prefix, \"input\", timestamp),\n",
    ")\n",
    "print('sample_label_png:', sample_label_png)\n",
    "\n",
    "manifest_file = sess.upload_data(\n",
    "    MANIFEST_LOCATION,\n",
    "    bucket=bucket,\n",
    "    key_prefix=os.path.join(prefix, \"input\", timestamp),\n",
    ")\n",
    "print('manifest_file:', manifest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(base_job_name=job_name,\n",
    "           image_uri=image_uri,\n",
    "           command=['python3'],\n",
    "           role=role,\n",
    "           instance_count=1,\n",
    "           instance_type='ml.c5.xlarge'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6fe68",
   "metadata": {},
   "source": [
    "以下のセルを実行すると、自動ラベリング検証ジョブが開始します。上記手順で Amazon CloudFront を作成している場合は、「クリックして自動ラベリング結果を確認する」と書かれたリンクから自動ラベリングされた画像をブラウザで確認することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5881de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "JST = tz.gettz('Asia/Tokyo')\n",
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "proc_output_bucket = bucket\n",
    "proc_output_prefix = job_name\n",
    "proc_output_s3_path = f's3://{proc_output_bucket}/{proc_output_prefix}/{project_name}/{timestamp}'\n",
    "\n",
    "base_model_path = 's3://xxx/output/model.tar.gz'\n",
    "\n",
    "processor.run(\n",
    "            job_name='autolabel-' + project_name + '-' + timestamp,\n",
    "            code=EVALUATION_SCRIPT_LOCATION, # S3 の URI でも可\n",
    "             inputs=[\n",
    "                     ProcessingInput(input_name='input',\n",
    "                                     source=os.path.dirname(sample_label_png),\n",
    "                                     destination=processing_input_dir)],\n",
    "             outputs=[ProcessingOutput(output_name='output',\n",
    "                                       source=processing_output_dir,\n",
    "                                      destination=proc_output_s3_path)],\n",
    "              arguments=[\n",
    "                  '--sample-png', os.path.basename(sample_label_png),\n",
    "                  '--manifest-file', os.path.basename(manifest_file),\n",
    "                  '--bucket-name', proc_output_bucket,\n",
    "                  '--data-output-path', proc_output_s3_path,\n",
    "                  '--role-arn', role,\n",
    "                  '--viewer-images-per-page', '10',\n",
    "                  '--class-num', '21',  # ラベルの分類クラス数\n",
    "                  '--background-class-id', '0',  # 背景に割り当てられたラベルID\n",
    "                  '--project-name', project_name,  # 検証結果を保存する S3 パスを作成するために使用\n",
    "                  '--confidence-thresh', '0.98',  # 自動ラベリング結果で最低限満たしてほしい画素単位の確信度\n",
    "                  '--total-confidence-thresh', '0.85',  # confidence-threshを超える画素が何割あれば採用するかを決める閾値\n",
    "                  '--num-manual-target', '1000',  # モデル再学習に必要な追加データセット数\n",
    "                  '--train_ratio', '0.8',  # データセットにおける学習データの割合。残りは検証データ\n",
    "                  '--timestamp', timestamp,\n",
    "#                   '--base-model-path', base_model_path,  # 追加学習をする場合はベースモデルの model.tar.gz が保存されている S3 パスを指定\n",
    "                  '--gt-job-name', gt_job_name,\n",
    "                  '--train-instance-type', 'ml.p2.8xlarge',\n",
    "                  '--input-dir', processing_input_dir,\n",
    "                  '--output-dir', processing_output_dir\n",
    "              ],\n",
    "              wait=False\n",
    "            )\n",
    "print('---------------------------------')\n",
    "print('Results will be saved here:', proc_output_s3_path)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "cloudfront_domain = f'https://{cloudfront_domain_name}'\n",
    "display(Markdown(f\"<a href=\\\"https://s3.console.aws.amazon.com/s3/buckets/{bucket}?region={region}&prefix={prefix}/{project_name}/{timestamp}/&showversions=false\\\" target=\\\"_blank\\\">クリックしてデータ保存場所に飛ぶ</a>\"))\n",
    "display(Markdown(f\"<a href=\\\"{cloudfront_domain}/{timestamp}/png_view/index.html\\\" target=\\\"_blank\\\">クリックして自動ラベリング結果を確認する</a>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911fdea",
   "metadata": {},
   "source": [
    "自動ラベリング検証ジョブが開始しました。このノートブックの構成の場合、ジョブの完了までに 2時間ほどかかります。ジョブの状況は SageMaker コンソールの左側のメニューにある[処理中]->[ジョブの処理]から確認できます。\n",
    "\n",
    "学習ジョブの入力に使用する manifest ファイル、自動ラベリング（バッチ推論）の出力などは上記セル実行時に出力されたパスに出力されます。このパス以下にイテレーション数を示す数字のフォルダが作成され、その中にそのイテレーションで生成されたファイルが保存されます。また以下のパス直下にある png フォルダの中には、自動ラベリングによって作成されたラベル画像が保存されます。\n",
    "\n",
    "```bash\n",
    "root \n",
    "|-0/\n",
    "  |-autolabel: バッチ推論の入出力ファイル\n",
    "  |-train: 学習ジョブの入出力ファイル（学習済みモデルのパスは学習ジョブが生成したパスに保存される）\n",
    "  |-updated-list: イテレーション官僚時点でのラベルあり画像となし画像のリスト\n",
    "|-1/\n",
    "|-2/\n",
    "|-png/: 自動ラベリングによって作成された PNG 画像\n",
    "|-png_view/: 自動ラベリングによって作成された PNG 画像と教師画像比較用データ\n",
    "|-report.txt: 何枚自動ラベリングされたかなどが記載されたレポート\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30adb64",
   "metadata": {},
   "source": [
    "## リソースの削除\n",
    "このノートブックで作成したリソースを削除します。他に、このノートブックを実行したノートブックインスタンスやデータを保存した Amazon S3 バケットも不要であれば削除してください。\n",
    "\n",
    "### ECR リポジトリの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b770b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_list = [\n",
    "    ecr_repository\n",
    "]\n",
    "for i in container_image_list:\n",
    "    try:\n",
    "        ecr_client.delete_repository(\n",
    "            repositoryName=i,\n",
    "            force=True\n",
    "        )\n",
    "        print('Delete:', i)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f85c92",
   "metadata": {},
   "source": [
    "### Amazon CloudFront と AWS WAF の削除\n",
    "\n",
    "CloudFront の削除には数分かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "response = cloudfront_client.get_distribution(\n",
    "    Id=cloudfront_id\n",
    ")\n",
    "etag = response['ETag']\n",
    "config = response['Distribution']['DistributionConfig']\n",
    "config['Enabled'] = False\n",
    "\n",
    "response = cloudfront_client.update_distribution(\n",
    "    Id=cloudfront_id,\n",
    "    IfMatch=etag,\n",
    "    DistributionConfig=config\n",
    ")\n",
    "\n",
    "while True:\n",
    "    response = cloudfront_client.get_distribution(\n",
    "        Id=cloudfront_id\n",
    "    )\n",
    "    etag = response['ETag']\n",
    "    if response['Distribution']['Status'] == 'InProgress':\n",
    "        time.sleep(60)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "response = cloudfront_client.delete_distribution(\n",
    "    Id=cloudfront_id,\n",
    "    IfMatch=etag\n",
    ")\n",
    "\n",
    "response = cloudfront_client.get_cloud_front_origin_access_identity(\n",
    "    Id=oai_id,\n",
    ")\n",
    "etag = response['ETag']\n",
    "response = cloudfront_client.delete_cloud_front_origin_access_identity(\n",
    "    Id=oai_id,\n",
    "    IfMatch=etag\n",
    ")\n",
    "\n",
    "response = waf2_client_us.delete_web_acl(\n",
    "    Name=acl_name,\n",
    "    Scope='CLOUDFRONT',\n",
    "    Id=acl_id,\n",
    "    LockToken=acl_lock_token\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
