{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e663d3",
   "metadata": {},
   "source": [
    "# Amazon SageMaker JumpStart で学習したモデルを使ってローカルで推論する\n",
    "\n",
    "Amazon SageMaker JumpStart で Tensorflow Hub や PyTorch Hub のモデルを転移学習させたあと、Deploy ボタンをクリックすることで学習みモデルがデプロイされた推論エンドポイントを立ち上げることができます。しかし、ユースケースによっては推論エンドポイントではなくローカルPCやその他の環境で学習済みモデルを使って推論を実行したい場合もあります。\n",
    "\n",
    "このノートブックでは、Amazon SageMaker JumpStart で学習したモデルを使って推論を実行します。PyTorch の VGG モデルを使う場合の方法を説明していますが、他のモデルや Tensorflow のモデルも同様の方法で推論が可能です（推論を実行するコードはフレームワークごとの書き方に変える必要があります）。\n",
    "\n",
    "## 学習済みモデルのダウンロードと解凍\n",
    "\n",
    "Amazon SageMaker の学習ジョブの機能を使ってモデルを学習すると、学習済みモデルは tar.gz で圧縮されて Amazon S3 に保存されます。まずは、S3 に保存された学習済みモデルをノートブックインスタンスにダウンロードします。今回は AWS CLI を使いますが、boto3 などを使っても OK です。\n",
    "\n",
    "**以下のコマンドの model.tar.gz のパスを、所望の学習済みモデルが保存された S3 パスに書き換えてから実行してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfaa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://bucket/job-name/output/model.tar.gz ./\n",
    "!tar zvxf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827c010",
   "metadata": {},
   "source": [
    "## モデルのロード\n",
    "\n",
    "model.tar.gz を解凍すると model.pt が作成されるので、それをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('model.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726e101",
   "metadata": {},
   "source": [
    "## 分類クラス情報の取得\n",
    "\n",
    "model.tar.gz を解凍すると、分類クラスが記載された class_label_to_prediction_index.json が作成されるので、これを読み込んで分類クラスの情報を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ccb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_open = open('class_label_to_prediction_index.json', 'r')\n",
    "json_load = json.load(json_open)\n",
    "class_names = []\n",
    "for v in json_load.keys():\n",
    "    class_names.append(v)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670abde6",
   "metadata": {},
   "source": [
    "## 前処理パラメタの取得\n",
    "\n",
    "機械学習モデルに入力する画像には前処理によって正規化されています。推論を実行する際にも学習時と同じ正規化のパラメタを使用する必要があります。そのため、学習の際に使用したソースコードを取得し、前処理に関するパラメタを確認します。\n",
    "\n",
    "モデルの学習に使用されたソースコードは、学習ジョブの詳細画面の「ハイパーパラメータ」の項目に、`sagemaker_submit_directory` として記録されたパスに保存されています。たとえば、`s3://bucket/job-name/source/sourcedir.tar.gz` と書かれています。この tar.gz ファイルをダウンロードして解凍します。\n",
    "\n",
    "**以下のコマンドの sourcedir.tar.gz のパスを、所望のソースコードが保存された S3 パスに書き換えてから実行してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56703130",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://bucket/job-name/source/sourcedir.tar.gz ./\n",
    "!tar zvxf sourcedir.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1c7e4",
   "metadata": {},
   "source": [
    "tar.gz ファイルを解凍すると、今回使用した VGG モデルの場合、`constants/constants.py` というファイルが作成されます。このファイルに、画像の前処理で使用するパラメタ `RANDOM_RESIZED_CROP`, `NORMALIZE_MEAN`, `NORMALIZE_STD` が記載されているので、以下のパラメタをコピーします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_RESIZED_CROP = 224\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a1d0b",
   "metadata": {},
   "source": [
    "コピーしたパラメタを使って、画像を変換するための transforms.Compose を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize(RANDOM_RESIZED_CROP),\n",
    "    transforms.CenterCrop(RANDOM_RESIZED_CROP),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ee1a3",
   "metadata": {},
   "source": [
    "## 推論の実行\n",
    "\n",
    "**下準備として、推論で使用する画像を images フォルダに保存してから、以降のセルを実行してください。**\n",
    "\n",
    "images フォルダの中のファイルを DataLoader で読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class ImageFolder(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        # 画像ファイルのパス一覧を取得する。\n",
    "        self.img_paths = glob.glob(img_dir + '/**')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.img_paths[index]\n",
    "        img = Image.open(path)\n",
    "        inputs = self.transform(img)\n",
    "\n",
    "        return {\"image\": inputs, \"path\": path}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "\n",
    "# Dataset を作成する。\n",
    "dataset = ImageFolder(\"images\", transform)\n",
    "# DataLoader を作成する。\n",
    "dataloader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60b376",
   "metadata": {},
   "source": [
    "images フォルダ内の画像を使って推論を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from torch.nn import functional as F\n",
    "\n",
    "for batch in dataloader:\n",
    "    inputs = batch[\"image\"].to(device)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    batch_probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "    batch_probs, batch_indices = batch_probs.sort(dim=1, descending=True)\n",
    "\n",
    "    for probs, indices, path in zip(batch_probs, batch_indices, batch[\"path\"]):\n",
    "        display.display(display.Image(path, width=RANDOM_RESIZED_CROP))\n",
    "        print(f\"path: {path}\")\n",
    "        for k in range(min(len(class_names), 3)):\n",
    "            print(f\"Top-{k + 1} {probs[k]:.2%} {class_names[indices[k]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
