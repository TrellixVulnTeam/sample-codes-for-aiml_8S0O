{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae485016",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Processing でデータ並列処理\n",
    "\n",
    "Amazon SageMaker Processing を使うと、任意のコンテナイメージやソースコードを使ってデータ処理を行うことができます。処理したいファイル数が多い場合、SageMaker Processing で複数のインスタンスにデータを分散させて並列処理するとデータ処理時間を短縮を狙えます。このノートブックでは、SageMaker Processing を使ってデータ並列処理する方法をご紹介します。\n",
    "\n",
    "## 使用するサービス\n",
    "- Amazon SageMaker\n",
    "- Amazon ECR\n",
    "- Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7a2e1",
   "metadata": {},
   "source": [
    "## docker イメージビルドのための下準備\n",
    "コンテナイメージビルドの際の容量不足を回避するために以下のセルを実行して docker 関連のファイルの保存場所を変更してください。以下のセルは、ノートブックインスタンス起動後1度だけ実行してください。インスタンスを再起動した際はディレクトリ構成が元に戻ってしまうため、再度実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2842e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo service docker stop\n",
    "sudo mv /var/lib/docker /home/ec2-user/SageMaker/docker\n",
    "sudo ln -s /home/ec2-user/SageMaker/docker /var/lib/docker\n",
    "sudo service docker start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5aeb2",
   "metadata": {},
   "source": [
    "## 設定\n",
    "SageMaker セッションを作成し、設定を開始します。入出力データを保存するための S3 バケットとプレフィックスは、ノートブックインスタンス、Processing Job と同じリージョン内にある必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "JST = tz.gettz('Asia/Tokyo')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/proc-pytorch-mnist'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "project_name = 'sagemaker-processing-parallel'\n",
    "user_name = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817e106",
   "metadata": {},
   "source": [
    "## データの取得\n",
    "\n",
    "このノートブックでは MNIST データセットを使用します。あとで画像のリサイズ処理をデータ並列処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz . --no-sign-request\n",
    "!tar -xvzf  mnist_png.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ad20c",
   "metadata": {},
   "source": [
    "SageMaker Processing は Amazon S3 に保存されたデータを入力データとして指定する仕組みになっているため、データを S3 にアップロードします。10000画像あるため、データのアップロードが完了するまでに 10分ほどかかるかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'mnist_png/testing'\n",
    "inputs = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d8d20",
   "metadata": {},
   "source": [
    "## SageMaker Processing の準備\n",
    "\n",
    "### コンテナイメージのビルドと Amazon ECR へのプッシュ\n",
    "\n",
    "SageMaker Processing は、データ処理に使用するコンテナイメージとスクリプトを個別に指定することができます。スクリプトをコンテナイメージの中に入れて実行することももちろん可能ですが、実行環境は変えずにスクリプトだけ変えたい場合もよくあると思うので、このノートブックではコンテナイメージとスクリプトを独立して扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p docker/prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/prepro/requirements.txt\n",
    "pandas==1.0.4\n",
    "Pillow==9.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/prepro/Dockerfile\n",
    "FROM python:3.8-slim-buster\n",
    "    \n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "RUN apt-get update -y && apt-get install -y libexpat1\n",
    "COPY requirements.txt .\n",
    "RUN pip3 install --upgrade pip\n",
    "RUN pip3 install -U --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7add2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_and_push_image(repo_name, docker_path, extra_accounts=[], tag = ':latest'):\n",
    "    uri_suffix = 'amazonaws.com'\n",
    "    repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, repo_name + tag)\n",
    "\n",
    "    !docker build -t $repo_name $docker_path\n",
    "    for a in extra_accounts:\n",
    "        !aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {a}.dkr.ecr.{region}.amazonaws.com\n",
    "    !aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n",
    "    !aws ecr create-repository --repository-name $repo_name\n",
    "    !docker tag {repo_name + tag} $repository_uri\n",
    "    !docker push $repository_uri\n",
    "    return repository_uri\n",
    "image_repository_uri = build_and_push_image(project_name + '-prepro-' + user_name, './docker/prepro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901ae35",
   "metadata": {},
   "source": [
    "## SageMaker Processing Job の実行\n",
    "\n",
    "以下のセルを実行すると、用意しておいたスクリプト [code/prepro.py](code/prepro.py) が SageMaker Processing Job として実行されます。以下の設定で Processing Job を実行すると、ml.t3.medium 4 台でデータ並列処理が実行され、処理が完了するまで 1時間ほどかかります。以下のセルで `Processor` を作成する際のパラメタ `instance_count` に 1を設定すると インスタンス 1台での処理となり Job の完了までに 3時間弱かかるため、データ並列処理の効果が出ているといえます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "job_name = project_name + '-' + user_name + '-' + timestamp\n",
    "code_path = '/opt/ml/processing/input/code'\n",
    "input_path = '/opt/ml/processing/input/data'\n",
    "output_path = '/opt/ml/processing/output/data'\n",
    "output_s3_path = f's3://{bucket}/{job_name}/output/result'\n",
    "\n",
    "processor = Processor(\n",
    "    image_uri=image_repository_uri,\n",
    "    entrypoint=[\"python3\", f\"{code_path}/prepro.py\"],\n",
    "#     env={\"ENV\": \"value\"},\n",
    "    role=role,\n",
    "    instance_count=4,\n",
    "    instance_type=\"ml.t3.medium\"\n",
    ")\n",
    "\n",
    "SCRIPT_LOCATION = \"code\"\n",
    "\n",
    "code_s3_path = sagemaker_session.upload_data(\n",
    "    SCRIPT_LOCATION,\n",
    "    bucket=bucket,\n",
    "    key_prefix=os.path.join(project_name, user_name, \"code\", timestamp),\n",
    ")\n",
    "code_s3_path\n",
    "\n",
    "\n",
    "processor.run(\n",
    "    job_name=job_name,\n",
    "#     code=code_s3_path,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name='code',\n",
    "            source=code_s3_path,\n",
    "            destination=code_path),\n",
    "        ProcessingInput(\n",
    "            input_name='data',\n",
    "            source=inputs,\n",
    "            destination=input_path,\n",
    "            s3_data_distribution_type='ShardedByS3Key')],\n",
    "     outputs=[\n",
    "         ProcessingOutput(\n",
    "             output_name='result',\n",
    "             source=output_path,\n",
    "             destination=output_s3_path,\n",
    "             s3_upload_mode='Continuous')],\n",
    "    arguments=['--code-path', code_path,\n",
    "              '--input-data-path', input_path,\n",
    "              '--output-data-path', output_path,\n",
    "              '--scale', '2.0'],\n",
    "    logs=False,\n",
    "    wait=False\n",
    ")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"<a href=\\\"https://s3.console.aws.amazon.com/s3/buckets/{bucket}?region={region}&prefix={job_name}/output/result/&showversions=false\\\" target=\\\"_blank\\\">検出結果の生データ (S3)</a>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adcc04",
   "metadata": {},
   "source": [
    "## 補足\n",
    "\n",
    "上記リンクをクリックすると、SageMaker Processing で処理された結果が保存された S3 パスにジャンプします。`algo-n.txt` というファイルが保存されていますが、このファイルには各インスタンスが処理した画像名が記録されています。ファイル名の `n` はインスタンスの ID を示します。このノートブックの例では 10000画像を入力画像として使用しており、4台のインスタンスでデータ並列処理を実行するとそれぞれのインスタンスに 2500画像ずつ分配されます。\n",
    "\n",
    "prepro.py では指定された倍率で入力画像をリサイズしています。最後に SageMaker がそれらの画像を S3 にアップロードします。リサイズ処理が高速すぎてデータ並列処理の効果が分かりにくかったため、70 行目に 1秒の sleep を入れました。インスタンスを起動したり入力データを S3 からダウンロードしたりするのにも時間がかかるため、データの数や処理時間によってはデータ分散の効果があまりえられないこともあります。ファイルサイズが小さいデータが大量にある場合（今回のようなケース）、ある程度の単位でデータを zip などでまとめるとデータのダウンロード時間を短縮できる可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa978f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
