{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Managed Spot Training ワークフローを構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、以下のようにインスタンスタイプのリストを実行時のパラメタとして指定すると、SageMaker 学習ジョブが正常に完了するまで指定されたインスタンスで学習ジョブを順に起動するワークフローを作成します。これにより、タイムアウトで学習ジョブが停止した場合でも、自動的に別のインスタンスタイプで学習ジョブを開始することができます。\n",
    "\n",
    "```json\n",
    "\"InstanceList\": [\n",
    "    [\n",
    "      \"ml.p3.2xlarge\",  # 使用したいインスタンス情報\n",
    "      \"spot\"              # スポットインスタンス\n",
    "    ],\n",
    "    [\n",
    "      \"ml.m5.xlarge\",\n",
    "      \"spot\"\n",
    "    ],\n",
    "    [\n",
    "      \"ml.c5.xlarge\",\n",
    "      \"ondemand\"      # オンデマンドインスタンス\n",
    "    ]\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "1. [背景](#背景)\n",
    "1. [セットアップ](#セットアップ)\n",
    "1. [S3 バケットの準備](#S3-バケットの準備)\n",
    "1. [データの準備](#データの準備)\n",
    "1. [学習ジョブの準備](#学習ジョブの準備)\n",
    "1. [Step Functions ループ制御用 Lambda 関数の準備](#Step-Functions-ループ制御用-Lambda-関数の準備)\n",
    "1. [AWS Step Functions の準備](#AWS-Step-Functions-の準備)\n",
    "1. [AWS Step Functions Workflow の実行](#AWS-Step-Functions-Workflow-の実行)\n",
    "1. [リソースの削除](#リソースの削除)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 背景\n",
    "\n",
    "Amazon SageMaker Managed Spot Training は、スポットインスタンスを使ってコスト効率よく機械学習モデルを学習するための機能です。スポットインスタンスは、通常のオンデマンドインスタンスよりも安く利用できますが、空きがなくなるとジョブが中断したり、スポットインスタンスを確保できずジョブが開始しない可能性があります。特に人気の高い GPU インスタンスは、スポットインスタンスの空きがないことも多くあります。そこで、Managed Spot Training ワークフローを作成して、学習ジョブ実行時に複数のインスタンスタイプを指定しておくことで、スポットインスタンスの空きがなく学習ジョブが正常完了しない場合は順次指定したインスタンスで学習ジョブを実行していき、ワークフロー完了時にいずれかの学習ジョブが正常完了するようにします。\n",
    "\n",
    "本ノートブックは、以下のようなワークフローを AWS Step Functions を使って構築します。ワークフロー実行時に、インスタンスタイプと、スポットインスタンスかオンデマンドインスタンスを示す文字列のリストが渡されるため、その値を確認してスポット学習か通常の学習ジョブのいずれかを指定されたインスタンスタイプで開始します。学習ジョブが終了したら終了ステータスを確認し、正常終了であればワークフローを終了します。何らかのエラーが発生していれば、次に指定されたインスタンスタイプと学習ジョブのタイプで学習ジョブを開始します。この処理を、リスト内の項目の数だけ繰り返します。\n",
    "\n",
    "<img src=\"workflow.png\" width=\"80%\">\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "### Step Functions Data Science SDK をインストール\n",
    "\n",
    "以下のセルを実行したら、**メニューの「Kernel」->「Restart」をクリックしてカーネルを再起動してください。**再起動後は以下のセルを再度実行する必要はないので、その下から作業を再開してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install -U awscli boto3 \"sagemaker>=2.0.0\"\n",
    "pip install -U \"stepfunctions==2.3.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SageMaker セッションを作成し、設定を開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "from time import sleep\n",
    "import utility\n",
    "\n",
    "project_name = 'sagemaker-spot'\n",
    "user_name = 'demo'\n",
    "\n",
    "JST = tz.gettz('Asia/Tokyo')\n",
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "iam_client = boto3.client('iam', region_name=region)\n",
    "sfn_client = boto3.client('stepfunctions', region_name=region)\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "sagemaker_policy_name = project_name + '-' + user_name + '-policy'\n",
    "prefix = f'sagemaker/{project_name}/{user_name}'\n",
    "bucket_name = project_name + '-' + user_name + '-' + timestamp\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "lambda_client = boto3.client('lambda', region_name=region)\n",
    "\n",
    "policy_arn_list = []\n",
    "role_name_list = []\n",
    "lambda_function_list = []\n",
    "\n",
    "role_name = role.split('/')[-1]\n",
    "iam_console_url = f'https://{region}.console.aws.amazon.com/iamv2/home#/roles/details/{role_name}?section=permissions'\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "text = f\"\"\"\n",
    "以下の手順で IAM 関連の設定を実施してください。\n",
    "1. <a href=\\\"policy/sagemaker-policy.json\\\" target=\\\"_blank\\\">policy/sagemaker-policy.json</a> の中身をコピー\n",
    "1. <a href=\\\"https://{region}.console.aws.amazon.com/iam/home#/policies$new?step=edit\\\" target=\\\"_blank\\\">IAM Policy の作成</a>をクリックし、**JSON** タブをクリックしてから手順1でコピーした JSON をペーストして右下の **次のステップ：タグ** ボタンをクリック\n",
    "1. 右下の **次のステップ：確認** ボタンをクリック\n",
    "1. **名前** に **「{sagemaker_policy_name}」** を記載して、右下の **ポリシーの作成** ボタンをクリック\n",
    "1.  <a href=\\\"{iam_console_url}\\\" target=\\\"_blank\\\">ノートブックインスタンスにアタッチされた IAM Role</a> を開く\n",
    "1. **許可を追加** ボタンをクリックして **ポリシーをアタッチ** を選択\n",
    "1. **その他の許可ポリシー** の検索ボックスで手順4 で作成した {sagemaker_policy_name} を検索して横にあるチェックボックスをオンにする\n",
    "1. **ポリシーのアタッチ** をクリック\n",
    "\"\"\"\n",
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 バケットの準備\n",
    "### Job 生成物格納用 S3 バケットの準備\n",
    "\n",
    "SageMaker Jobs が生成したデータやモデルなどを保存する S3 バケットを作成します。セキュリティのため暗号化を有効にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.create_bucket(bucket_name, region, account_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "\n",
    "このサンプルノートブックでは、手書き数字のデータセット MNIST を使用します。\n",
    "\n",
    "### データの取得\n",
    "\n",
    "AWS が用意した S3 バケットからデータをダウンロードして展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz . --no-sign-request\n",
    "!tar -xvzf  mnist_png.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータを pt 形式で保存します。このノートブックでは pt 形式を使用しますが、データ形式はご自身の使用する学習スクリプトに合わせて変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "\n",
    "data_dir =  'data'\n",
    "training_dir = 'mnist_png/training'\n",
    "test_dir = 'mnist_png/testing'\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "training_data = datasets.ImageFolder(root=training_dir,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Grayscale(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Grayscale(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "training_data_loader = DataLoader(training_data, batch_size=len(training_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(data_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(data_dir, 'test.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データを S3 にアップロードする\n",
    "SageMaker 学習ジョブを使う場合は、学習データが S3 に保存されている必要があります。データセットを S3 にアップロードするには、 `sagemaker.Session.upload_data` 関数を使用します。 戻り値として入力した S3 のロケーションは、後で学習ジョブを実行するときに使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=data_dir, bucket=bucket_name, key_prefix=os.path.join(prefix, 'data'))\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ジョブの準備\n",
    "### 学習スクリプトを S3 にアップロードする\n",
    "\n",
    "学習ジョブで使用する学習スクリプトを tar.gz で圧縮して S3 にアップロードします。SageMaker Python SDK の Estimator を使う場合はこの処理に相当する部分は SDK がやってくれますが、Step Functions から学習ジョブを実行する際は低レイヤの API が使用されるため、自分でスクリプトを S3 にアップロードしておく必要があります。\n",
    "\n",
    "スポット学習ジョブが中断された後、再度スポットインスタンスに空きがでて、指定された待機時間内であればジョブが再開します。その際に、チェックポイントを利用することで、モデルの学習を中断前の続きから実施することができます。チェックポイント機能を活用するには、asl.json の `CheckpointConfig` にチェックポイントを保存するためのローカルパスと S3 パスを指定し、学習スクリプトにチェックポイントの保存と読み込みのコードを書けば OK です。このサンプルではチェックポイントを利用するよう構成されています。スポット学習の状態遷移については [こちらのドキュメント](https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/model-managed-spot-training.html#model-managed-spot-training-status) を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now(tz=JST).strftime('%Y%m%d-%H%M')\n",
    "\n",
    "TRAINNING_SCRIPT_LOCATION = \"source.tar.gz\"\n",
    "!cd code/sagemaker && tar zcvf ../../$TRAINNING_SCRIPT_LOCATION train.py\n",
    "\n",
    "train_code = sagemaker_session.upload_data(\n",
    "    TRAINNING_SCRIPT_LOCATION,\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=os.path.join(project_name, user_name, \"train/code\", timestamp),\n",
    ")\n",
    "train_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習時に使用するコンテナイメージの URI を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "pytorch_training_image_uri = retrieve('pytorch',\n",
    "                                       region,\n",
    "                                       version='1.10',\n",
    "                                       py_version='py38',\n",
    "                                       instance_type = 'ml.m5.xlarge',\n",
    "                                       accelerator_type=None,\n",
    "                                       image_scope='training')\n",
    "pytorch_training_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Functions ループ制御用 Lambda 関数の準備\n",
    "\n",
    "Step Functions ワークフローでループ処理をするために必要な Lambda 関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sfn_loop_function_name  = project_name + 'lambda-sfn-loop-' + user_name\n",
    "lambda_sfn_loop_policy_name = lambda_sfn_loop_function_name + '-policy'\n",
    "lambda_sfn_loop_role_name = lambda_sfn_loop_function_name + '-role'\n",
    "lambda_sfn_loop_json_name = 'lambda-sfn-loop-policy.json'\n",
    "\n",
    "assume_role_policy = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [{\"Sid\": \"\",\"Effect\": \"Allow\",\"Principal\": {\"Service\":\"lambda.amazonaws.com\"},\"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "lambda_sfn_loop_role_arn = utility.create_policy_role(\n",
    "                    lambda_sfn_loop_policy_name, lambda_sfn_loop_json_name,\n",
    "                    lambda_sfn_loop_role_name, assume_role_policy,\n",
    "                    role_name_list, policy_arn_list)\n",
    "sleep(10) # wait until IAM is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルでは、Lambda 関数で使用するライブラリとソースコードを zip に固めています。このサンプルでは特にライブラリをインストールする必要はありませんが、ライブラリをインストールする際は、以下の処理を実行した環境と同じ Python のバージョンのランタイムを指定してください。2022年8月現在、conda_python3 カーネルの Python バージョンは 3.8 なので、Lambda 関数の Python バージョンも 3.8 を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_lambda_resource(function_name, code_path):\n",
    "    !rm -rf $function_name\n",
    "    !rm {function_name}.zip\n",
    "    !mkdir $function_name\n",
    "#     !pip install pyyaml -t $function_name  # ライブラリのインストール例\n",
    "    !cp {code_path}/index.py $function_name\n",
    "    !cd $function_name && zip -r ../{function_name}.zip .\n",
    "prepare_lambda_resource(lambda_sfn_loop_function_name, 'code/lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した zip ファイルを使って Lambda 関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sfn_loop_function_arn = utility.create_lambda_function(lambda_sfn_loop_function_name,\n",
    "                                                   lambda_sfn_loop_function_name,\n",
    "                                                   lambda_sfn_loop_role_arn,\n",
    "                                                   'index',\n",
    "                                                   lambda_function_list,\n",
    "                                                   py_version='python3.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Step Functions の準備\n",
    "\n",
    "あらかじめ用意してある JSON 形式の定義ファイルを使って、冒頭に示した Step Functions Workflow を作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Role と Policy の作成\n",
    "\n",
    "Step Functions の Workflow にセットする IAM Role を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "step_functions_policy_name = project_name + '-sfn-' + user_name + '-policy'\n",
    "step_functions_role_name = project_name + '-sfn-' + user_name + '-role'\n",
    "step_functions_policy_json_name = 'stepfunctions-policy.json'\n",
    "\n",
    "assume_role_policy = {\n",
    "      \"Version\": \"2012-10-17\",\n",
    "      \"Statement\": [{\"Sid\": \"\",\"Effect\": \"Allow\",\"Principal\": {\"Service\":\"states.amazonaws.com\"},\"Action\": \"sts:AssumeRole\"}]\n",
    "    }\n",
    "\n",
    "workflow_execution_role = utility.create_policy_role(\n",
    "                    step_functions_policy_name, step_functions_policy_json_name,\n",
    "                    step_functions_role_name, assume_role_policy,\n",
    "                    role_name_list, policy_arn_list)\n",
    "workflow_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Functions ワークフローの作成\n",
    "\n",
    "学習ジョブが正常終了しない場合、DescribeTrainingJob API を実行した結果が Lambda 関数に渡されるので、SNS への通知などエラーの種類に応じた処理をすることができます。ワークフロー実行時の入力パラメタを追加、変更したい場合は asl.json を変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "asl_file = 'asl.json'\n",
    "workflow_name = project_name + '-' + user_name\n",
    "try:\n",
    "    response = sfn_client.create_state_machine(\n",
    "        name=workflow_name,\n",
    "        definition=open(asl_file).read(),\n",
    "        roleArn=workflow_execution_role,\n",
    "        type='STANDARD'\n",
    "    )\n",
    "    workflow_arn = response['stateMachineArn']\n",
    "    print('Workflow created.')\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'StateMachineAlreadyExists':\n",
    "        workflow_arn = utility.get_sfn_workflow_arn(workflow_name)\n",
    "        response = sfn_client.update_state_machine(\n",
    "            stateMachineArn=workflow_arn,\n",
    "            definition=open(asl_file).read(),\n",
    "            roleArn=workflow_execution_role\n",
    "        )\n",
    "        print('Workflow updated.')\n",
    "    else:\n",
    "        print(e)\n",
    "\n",
    "workflow_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Functions ワークフローの実行\n",
    "\n",
    "実行時パラメタを指定して、ワークフローを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.workflow import Workflow\n",
    "workflow = Workflow.attach(workflow_arn)\n",
    "\n",
    "sfn_timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "job_name = project_name + '-' + user_name + '-' + sfn_timestamp\n",
    "\n",
    "checkpoint_s3_path = f's3://{bucket_name}/{prefix}/checkpoint'\n",
    "\n",
    "execution = workflow.execute(\n",
    "    inputs={\n",
    "        # Step Functions Workflow Settings\n",
    "        \"counter\": 0,  # カウンタ初期化\n",
    "        \"LambdaFunctionARN\": f\"{lambda_sfn_loop_function_arn}:$LATEST\",\n",
    "        # SageMaker Settings\n",
    "        \"EnableManagedSpotTraining\": \"true\",\n",
    "        \"TrainingJobName\": job_name,\n",
    "        \"TrainingImage\": pytorch_training_image_uri,\n",
    "        \"S3OutputPath\": f\"s3://{bucket_name}/{prefix}\",\n",
    "        \"RoleArn\": role,\n",
    "        \"TrainingParameters\": {\n",
    "            \"sagemaker_program\": \"train.py\",\n",
    "            \"sagemaker_submit_directory\": train_code,\n",
    "            \"epochs\": \"5\"\n",
    "        },\n",
    "        \"TrainingDataS3Path\": inputs,\n",
    "        \"CheckPointS3Path\": checkpoint_s3_path,\n",
    "        \"SpotMaxRuntimeInSeconds\": 10,\n",
    "        \"SpotMaxWaitTimeInSeconds\": 10,\n",
    "        \"OndemandMaxRuntimeInSeconds\": 60*60*24,  # 24 hours\n",
    "#         \"StoppingCondition\":{\n",
    "#           \"MaxRuntimeInSeconds\": 60,\n",
    "#           \"MaxWaitTimeInSeconds\": 60\n",
    "#         },\n",
    "        \"InstanceList\": [  # 使用したいインスタンス情報\n",
    "            [\n",
    "              \"ml.m5.xlarge\",\n",
    "              \"spot\"\n",
    "            ],\n",
    "            [\n",
    "              \"ml.p3.2xlarge\",\n",
    "              \"spot\"\n",
    "            ],\n",
    "            [\n",
    "              \"ml.c5.xlarge\",\n",
    "              \"ondemand\"\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"<a href=\\\"https://{region}.console.aws.amazon.com/states/home?region={region}#/executions/details/{execution.execution_arn}\\\" target=\\\"_blank\\\">Step Functions のコンソール</a>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Functions Workflow の動作確認\n",
    "\n",
    "上記セルを実行した際に表示されたリンクから AWS コンソールに移動して今実行した Workflow を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リソースの削除\n",
    "\n",
    "今回作成したリソースは基本的に利用時のみに料金が発生するものですが、意図しない課金を防ぐために、不要になったらこのノートブックで作成したリソースを削除しましょう。\n",
    "\n",
    "### Step Functions Workflow の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_list = Workflow.list_workflows()\n",
    "workflow_arn = [d['stateMachineArn'] for d in workflow_list  if d['name']==workflow_name][0]\n",
    "sfn_workflow = Workflow.attach(workflow_arn)\n",
    "try:\n",
    "    sfn_workflow.delete()\n",
    "    print('Delete:', workflow_name)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda 関数の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_function_list = list(set(lambda_function_list))\n",
    "for f in lambda_function_list:\n",
    "    lambda_client.delete_function(FunctionName=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 バケットの削除\n",
    "\n",
    "S3 バケットを削除したい場合は、以下のセルのコメントアウトを外してから実行してバケットを空にしてください。その後、S3 のコンソールからバケットの削除を実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def delete_all_keys_v2(bucket, prefix, dryrun=False):\n",
    "#     contents_count = 0\n",
    "#     marker = ''\n",
    "\n",
    "#     while True:\n",
    "#         if marker == '':\n",
    "#             response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "#         else:\n",
    "#             response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=marker)\n",
    "\n",
    "#         if 'Contents' in response:\n",
    "#             contents = response['Contents']\n",
    "#             contents_count = contents_count + len(contents)\n",
    "#             for content in contents:\n",
    "#                 if not dryrun:\n",
    "#                     print(\"Deleting: s3://\" + bucket + \"/\" + content['Key'])\n",
    "#                     s3_client.delete_object(Bucket=bucket, Key=content['Key'])\n",
    "#                 else:\n",
    "#                     print(\"DryRun: s3://\" + bucket + \"/\" + content['Key'])\n",
    "\n",
    "#         if 'NextContinuationToken' in response:\n",
    "#             marker = response['NextContinuationToken']\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "#     print(contents_count, 'file were deleted.')\n",
    "\n",
    "# delete_all_keys_v2(bucket_name, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Role と Policy の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name_list = list(set(role_name_list))\n",
    "policy_arn_list = list(set(policy_arn_list))\n",
    "\n",
    "utility.delete_role_policy(role_name_list, policy_arn_list)\n",
    "\n",
    "# ノートブックインスタンスにアタッチしたポリシーの削除\n",
    "sagemaker_policy_arn = utility.get_policy_arn(sagemaker_policy_name)\n",
    "response = iam_client.detach_role_policy(\n",
    "    RoleName=role.split('/')[2],\n",
    "    PolicyArn=sagemaker_policy_arn\n",
    ")\n",
    "print('\\nこちらの IAM Policy は手動で削除してください。', sagemaker_policy_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.382px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
