{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49eb8a2d",
   "metadata": {},
   "source": [
    "# Amazon SageMaker で DeOldify を動かしてモノクロ画像をカラーにする \n",
    "\n",
    "このノートブックでは、モノクロ画像をカラー化するモデル [DeOldify](https://github.com/jantic/DeOldify) の学習済みモデルを Amazon SageMaker Processing を使って実行します。あらかじめ Amazon S3 にモノクロ画像を保存しておき、Processing Job 実行時にそのパスを指定することで、指定されたパスの中のモノクロ画像が全てカラー化されて Amazon S3 に保存されます。\n",
    "\n",
    "## 準備\n",
    "**このサンプルでは、カスタムコンテナを Amazon ECR に push する必要があります。**以下の操作でこのノートブックインスタンスで使用している IAM ロールに Amazon ECR にイメージを push するための権限を追加してください。\n",
    "\n",
    "1. Amazon SageMaker コンソールからこのノートブックインスタンスの詳細画面を表示<br>\n",
    "（左側のメニューのインスタンス -> ノートブックインスタンス -> インスタンス名をクリック）\n",
    "1. 「アクセス許可と暗号化」の「IAM ロール ARN」のリンクをクリック（IAM のコンソールに遷移します）\n",
    "1. 「ポリシーをアタッチします」と書いてある青いボタンをクリック\n",
    "1. 検索ボックスに ec2containerregistry と入力し AmazonEC2ContainerRegistryFullAccess のチェックボックスをチェックする\n",
    "1. 「ポリシーのアタッチ」と書いてある青いボタンをクリック\n",
    "\n",
    "\n",
    "以下のセルでは、Amazon SageMaker を使うためのセットアップを行います。ロールの情報、ノートブックインスタンスのリージョン、アカウントID などの情報を取得しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import boto3\n",
    "import sys\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "session = sagemaker.Session()\n",
    "s3_output = session.default_bucket()\n",
    "s3_prefix = 'deoldify-BYO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fed7de",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Processing で DeOldify を実行\n",
    "\n",
    "まずは Processing Job で使用する Docker コンテナイメージを作成します。必要なファイルは wget や git clone で取得してコンテナイメージの中に入れておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p docker-proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-proc/Dockerfile\n",
    "\n",
    "FROM nvcr.io/nvidia/pytorch:19.04-py3\n",
    "    \n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "ENV TZ=Asia/Tokyo \n",
    "\n",
    "RUN apt-get -y update && apt-get install -y \\\n",
    "\tpython3-pip \\\n",
    "\tsoftware-properties-common \\\n",
    "\twget \\\n",
    "\tffmpeg \\\n",
    "\tgit\n",
    "\n",
    "RUN mkdir -p /root/.torch/models\n",
    "\n",
    "RUN mkdir -p /data/models\n",
    "\n",
    "RUN mkdir -p /data/gitrepo\n",
    "RUN cd /data/gitrepo && git clone https://github.com/jantic/DeOldify.git\n",
    "\n",
    "RUN wget -O /root/.torch/models/vgg16_bn-6c64b313.pth https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\n",
    "\n",
    "RUN wget -O /root/.torch/models/resnet34-333f7ec4.pth https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "\n",
    "RUN pip install --upgrade pip \\\n",
    "\t&& pip install versioneer==0.18 \\\n",
    "\t\ttensorboardX==1.6 \\\n",
    "\t\tFlask==1.1.1 \\\n",
    "\t\tpillow==6.1 \\\n",
    "\t\tnumpy==1.16 \\\n",
    "\t\tscikit-image==0.15.0 \\\n",
    "\t\trequests==2.21.0 \\\n",
    "\t\tffmpeg-python==0.2.0 \\\n",
    "\t\tyoutube-dl>=2019.4.17 \\\n",
    "\t\tjupyterlab==1.2.4 \\\n",
    "\t\topencv-python>=3.3.0.10 \\\n",
    "\t\tfastai==1.0.51\n",
    "\n",
    "ADD . /data/\n",
    "\n",
    "WORKDIR /data\n",
    "\n",
    "# force download of file if not provided by local cache\n",
    "RUN [[ ! -f /data/models/ColorizeArtistic_gen.pth ]] && wget -O /data/models/ColorizeArtistic_gen.pth https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth\n",
    "RUN [[ ! -f /data/models/ColorizeVideo_gen.pth ]] && wget -O /data/models/ColorizeVideo_gen.pth https://data.deepai.org/deoldify/ColorizeVideo_gen.pth\n",
    "\n",
    "EXPOSE 8888\n",
    "EXPOSE 5000\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENTRYPOINT [\"python3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_repository = 'deoldify-byo-proc'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766914ac",
   "metadata": {},
   "source": [
    "コンテナイメージを build して Amazon ECR に push します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387a31d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository docker-proc\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4298c",
   "metadata": {},
   "source": [
    "上記セルでコンテナイメージを build する際に no space left というエラーが出たら以下のセルのコメントを外して実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3084ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !docker system prune -a -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa72f5",
   "metadata": {},
   "source": [
    "以下のセルは DeOldify を使って、指定された Amazon S3 パスに保存されているモノクロ画像をカラー化して保存するスクリプトです。カラー化した画像は指定された Amazon S3 パスにアップロードされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/gitrepo/DeOldify')\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import shutil\n",
    "    \n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "import torch\n",
    "from os import path\n",
    "import fastai\n",
    "from deoldify.visualize import *\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input-dir', type=str, default=None)\n",
    "    parser.add_argument('--output-dir', type=str, default=None)\n",
    "    parser.add_argument('--render-factor', type=str, default='35')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    #choices:  CPU, GPU0...GPU7\n",
    "    device.set(device=DeviceId.GPU0)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print('GPU not available.')\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")\n",
    "    \n",
    "    colorizer = get_image_colorizer(artistic=True)\n",
    "    colorizer_video = get_video_colorizer()\n",
    "    \n",
    "    file_list = glob.glob(args.input_dir + '/**')\n",
    "    \n",
    "    render_factor = int(args.render_factor)  #@param {type: \"slider\", min: 7, max: 40}\n",
    "    watermarked = False #@param {type:\"boolean\"}\n",
    "    \n",
    "    for f in file_list:\n",
    "        \n",
    "        print('file: ' + os.path.basename(f) + ' is processing.')\n",
    "        root, ext = os.path.splitext(f)\n",
    "\n",
    "        if f is not None and f !='':\n",
    "            if ext in ['.jpg', '.jpeg', '.png']:\n",
    "                colorizer.plot_transformed_image(f, results_dir=Path(args.output_dir), render_factor=render_factor, display_render_factor=True, figsize=(8,8))\n",
    "            else:\n",
    "                print(f + ' is not image file.')\n",
    "        else:\n",
    "            print('Provide an image url and try again.')\n",
    "\n",
    "    print('====results====')\n",
    "    print(glob.glob(args.output_dir + '/**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83fbbfe",
   "metadata": {},
   "source": [
    "作成したコンテナイメージとスクリプトを使って DeOldify を実行します。`ScriptProcessor` を作成する際に、使用するインスタンスタイプを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                                   image_uri=processing_repository_uri,\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.c5.4xlarge')\n",
    "#                                    instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea9aa1",
   "metadata": {},
   "source": [
    "すべてのセットアップが終わったら Processing Job を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2110da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from time import gmtime, strftime \n",
    "\n",
    "processing_job_name = \"deoldify-byo-process-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "output_destination = 's3://{}/{}/data'.format(s3_output, s3_prefix)\n",
    "input_s3 = 's3://data-for-experiments/images/monochrome-images/'\n",
    "\n",
    "local_input_path = '/opt/ml/processing/input/data'\n",
    "local_output_path = '/opt/ml/processing/output'\n",
    "\n",
    "script_processor.run(code='preprocessing.py',\n",
    "                      job_name=processing_job_name,\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_s3,\n",
    "                        destination=local_input_path)],\n",
    "                      outputs=[ProcessingOutput(output_name='output',\n",
    "                                                destination='{}/{}'.format(output_destination, processing_job_name),\n",
    "                                                source=local_output_path)],\n",
    "                      arguments=[\n",
    "                          '--input-dir',local_input_path,\n",
    "                          '--output-dir',local_output_path,\n",
    "                          '--render-factor',\"35\"\n",
    "                      ]\n",
    "                    )\n",
    "\n",
    "preprocessing_job_description = script_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06f0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
