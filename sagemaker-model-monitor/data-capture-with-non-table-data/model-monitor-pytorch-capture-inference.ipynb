{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e1d4e7",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Model Monitor の機能を使って PyTorch の MNIST 分類モデルの推論入出力をキャプチャする\n",
    "\n",
    "[Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) は推論エンドポイントにデプロイされたモデルの性能を監視するためのサービスですが、2022年1月現在、ほとんどの機能はテーブルデータのみの対応です。しかし、推論リクエスト時の入出力データをキャプチャする機能はテーブルデータでなくても利用することができるので、PyTorch の MNIST 分類モデルをサンプルに使い方をご紹介します。\n",
    "\n",
    "キャプチャした入力データを使って Ground Truth データ（正解データ）を作り、キャプチャした出力データ（推論結果）と比較すれば、正解率などのメトリクスを算出することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9780a2",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#SDK-の更新\" data-toc-modified-id=\"SDK-の更新-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>SDK の更新</a></span></li><li><span><a href=\"#セットアップ\" data-toc-modified-id=\"セットアップ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>セットアップ</a></span></li><li><span><a href=\"#学習データの準備\" data-toc-modified-id=\"学習データの準備-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>学習データの準備</a></span></li><li><span><a href=\"#デプロイするモデルの学習\" data-toc-modified-id=\"デプロイするモデルの学習-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>デプロイするモデルの学習</a></span></li><li><span><a href=\"#モデルのデプロイ\" data-toc-modified-id=\"モデルのデプロイ-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>モデルのデプロイ</a></span></li><li><span><a href=\"#データキャプチャを試す\" data-toc-modified-id=\"データキャプチャを試す-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>データキャプチャを試す</a></span></li><li><span><a href=\"#エンドポイントの削除\" data-toc-modified-id=\"エンドポイントの削除-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>エンドポイントの削除</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2f896",
   "metadata": {},
   "source": [
    "## SDK の更新\n",
    "最新の Amazon SageMaker Python SDK と AWS SDK for Python をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip --quiet\n",
    "!{sys.executable} -m pip install -U awscli sagemaker boto3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90382d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eab904",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "使用するモジュールのインポートやパラメタの設定などを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tempfile import TemporaryFile\n",
    "import time\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_runtime = boto_session.client(\"sagemaker-runtime\")\n",
    "region = boto_session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "# Configuration:\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = \"mnist\"\n",
    "output_path = f\"s3://{bucket_name}/{prefix}\"\n",
    "data_capture_prefix = f\"{prefix}/monitoring/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket_name}/{data_capture_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = f\"s3://{bucket_name}/{prefix}\"\n",
    "# data_capture_prefix = f\"{prefix}/monitoring/datacapture\"\n",
    "# s3_capture_upload_path = f\"s3://{bucket_name}/{data_capture_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "NOTEBOOK_METADATA_FILE = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "if os.path.exists(NOTEBOOK_METADATA_FILE):\n",
    "    with open(NOTEBOOK_METADATA_FILE, \"rb\") as f:\n",
    "        metadata = json.loads(f.read())\n",
    "        domain_id = metadata.get(\"DomainId\")\n",
    "        on_studio = True if domain_id is not None else False\n",
    "print(\"Is this notebook runnning on Studio?: {}\".format(on_studio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec640d7c",
   "metadata": {},
   "source": [
    "## 学習データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz . --no-sign-request\n",
    "if on_studio:\n",
    "    !tar -xzf mnist_png.tgz -C /opt/ml --no-same-owner\n",
    "else:\n",
    "    !tar -xvzf  mnist_png.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a610f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "\n",
    "root_dir_studio = '/opt/ml'\n",
    "data_dir = os.path.join(root_dir_studio,'data') if on_studio else 'data'\n",
    "training_dir = os.path.join(root_dir_studio,'mnist_png/training') if on_studio else 'mnist_png/training'\n",
    "test_dir = os.path.join(root_dir_studio,'mnist_png/testing') if on_studio else 'mnist_png/testing'\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "training_data = datasets.ImageFolder(root=training_dir,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Grayscale(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Grayscale(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "training_data_loader = DataLoader(training_data, batch_size=len(training_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(data_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(data_dir, 'test.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871020d",
   "metadata": {},
   "source": [
    "以下のセルを実行して、学習データを Amazon S3 にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c37fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=data_dir, bucket=bucket_name, key_prefix=os.path.join(prefix, 'data'))\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824e9a1",
   "metadata": {},
   "source": [
    "以下のセルを実行して、モデルをデプロイした後の推論テストに使う画像を確認します。データセットからランダムjに5枚の画像をピックアップしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw_test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                        transform=transforms.Compose([\n",
    "                                        transforms.Grayscale(),\n",
    "                                        transforms.ToTensor()]))\n",
    "num_samples = 5\n",
    "indices = random.sample(range(len(raw_test_data) - 1), num_samples)\n",
    "raw_images = np.array([raw_test_data[i][0].numpy() for i in indices])\n",
    "raw_labels = np.array([raw_test_data[i][1] for i in indices])\n",
    "\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(raw_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(raw_labels[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "images = np.array([test_data[i][0].numpy() for i in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff0e9f",
   "metadata": {},
   "source": [
    "## デプロイするモデルの学習\n",
    "MNIST 分類モデルを学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import image_uris\n",
    "\n",
    "# # Specify an AWS container image and region as desired\n",
    "# container = image_uris.retrieve(\n",
    "#     region=region, framework=\"pytorch\", \n",
    "#     version=\"1.8.1\", instance_type='ml.c5.xlarge', image_scope='training', py_version='py36')\n",
    "# container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66462489",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "        entry_point=\"train.py\",\n",
    "        source_dir=\"code\",  # directory of your training script\n",
    "        role=role,\n",
    "        framework_version=\"1.8.0\",\n",
    "        py_version=\"py3\",\n",
    "        instance_type=\"ml.c4.xlarge\",\n",
    "        instance_count=1,\n",
    "#         output_path=output_path,\n",
    "        hyperparameters={\n",
    "                        'batch-size':128,\n",
    "                        'lr': 0.01,\n",
    "                        'epochs': 10,\n",
    "                        'backend': 'gloo'\n",
    "                    },\n",
    "    )\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae612a",
   "metadata": {},
   "source": [
    "## モデルのデプロイ\n",
    "学習したモデルを推論エンドポイントにデプロイします。推論エンドポイントが InService になるまで数分かかります。デプロイの際にデータキャプチャ設定を `data_capture_config` に設定します。このサンプルでは、トラフィックの100%をキャプチャするよう設定しています。キャプチャされたデータは `destination_s3_uri` で指定した S3 パスに保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "endpoint_name = \"DEMO-pytorch-mnist-model-monitor-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "print(endpoint_name)\n",
    "\n",
    "model = estimator.create_model(role=role, source_dir=\"code\", entry_point=\"inference.py\")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=DataCaptureConfig(\n",
    "        enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe4c23",
   "metadata": {},
   "source": [
    "## データキャプチャを試す\n",
    "\n",
    "推論エンドポイントが起動したら、テストデータを使って推論を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(images)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "\n",
    "print('The GT labels are: {}'.format(raw_labels))\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef3492",
   "metadata": {},
   "source": [
    "キャプチャされたデータはエンドポイント作成時に指定したパスの下の `エンドポイント名/AllTraffic/yyyy/mm/dd/hh/` に JSONL 形式で保存されます。以下のセルを実行して、保存された JSONL ファイルのリストを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471251ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=bucket_name, Prefix=data_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0cb85",
   "metadata": {},
   "source": [
    "以下のセルを実行して、JSONL ファイルの中を見てみましょう。`\"encoding\": \"BASE64\"` と書かれていることから、base64 形式にエンコードされていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa08b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket_name, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = json.loads(get_obj_body(capture_files[-1]))\n",
    "\n",
    "print(json.dumps(capture_file, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a06fb6",
   "metadata": {},
   "source": [
    "以下のセルを実行して、キャプチャデータをデコードして表示します。このサンプルは推論の入力形式が Numpy ですが、上記セルで確認したようにキャプチャされたデータは base64 形式にデコードされて JSONL ファイルに記載されています。入力データと出力データ（推論結果）をデコードして表示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf140c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "input_npy = base64.b64decode(capture_file['captureData']['endpointInput']['data'].encode())\n",
    "output_npy = base64.b64decode(capture_file['captureData']['endpointOutput']['data'].encode())\n",
    "\n",
    "input_data = np.load(BytesIO(input_npy))\n",
    "output_data = np.load(BytesIO(output_npy))\n",
    "\n",
    "print('---- input data ---- size:', np.shape(input_data))\n",
    "print(input_data)\n",
    "print('---- output data ---- size:', np.shape(output_data))\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84139f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = output_data.argmax(axis=1)\n",
    "\n",
    "print('The GT labels are: {}'.format(raw_labels))\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbd64c",
   "metadata": {},
   "source": [
    "## エンドポイントの削除\n",
    "以下のセルを実行して、作成したエンドポイントを削除します。エンドポイントは明示的に削除しない限り課金が発生するので、不要になったら必ず削除してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcff11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p37",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.113px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
