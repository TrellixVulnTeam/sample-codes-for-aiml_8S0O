{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 類似画像検索のサンプルノートブック\n",
    "このノートブックは、機械学習と Amazon Elasticsearch Service (Amazon ES) を使って類似画像検索を行うサンプルノートブックです。このノートブックは、conda_mxnet_p36 カーネルで実行してください。<br>\n",
    "[こちら](https://aws.amazon.com/jp/builders-flash/202102/elasticsearch-your-cat/) の記事の手順で Amazon Elasticsearch Service と Kibana の設定が完了してからこのノートブックを実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パスの設定\n",
    "このノートブックを実行する前に、ご自身の環境に合わせて以下を設定してください。\n",
    "\n",
    "* `es_host` に、Amazon Elasticsearch Service のドメインのエンドポイント名を記載します。<br>\n",
    "* `region` に、このノートブックインスタンスのリージョンを記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_host = 'esdomainname.ap-northeast-1.es.amazonaws.com'\n",
    "region = 'ap-northeast-1' # e.g. us-west-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行環境の設定\n",
    "このサンプルでは、画像を特徴ベクトルに変換するために MXNet Gluon の学習済みの機械学習モデルを使用するため、gluoncv をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import multiprocessing\n",
    "from mxnet.gluon.data.vision.datasets import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "import numpy as np\n",
    "# import wget\n",
    "import imghdr\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob, os, time\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "import urllib.parse\n",
    "import urllib\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "import glob\n",
    "from os.path import join\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習モデルの設定\n",
    "このサンプルでは、画像から特徴ベクトルに変換するために学習済みの機械学習モデルを使用します。\n",
    "ここでは、MXNet の model-zoo のモデルを使用します。model-zoo のネットワークは、特徴量が .features プロパティにあり、出力が .output プロパティにあります。この仕組みを利用して、事前にトレーニングされたネットワークを使って featurizer を非常に簡単に作成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EMBEDDING_SIZE = 512\n",
    "SIZE = (224, 224)\n",
    "MEAN_IMAGE= mx.nd.array([0.485, 0.456, 0.406])\n",
    "STD_IMAGE = mx.nd.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if len(mx.test_utils.list_gpus()) else mx.cpu()\n",
    "net = vision.resnet18_v2(pretrained=True, ctx=ctx).features\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの準備\n",
    "### データの変換\n",
    "モデルの入力サイズに合わせるため、元画像をリサイズとクロップしてサイズを 224 x 224 にして画素値を 0 から 1 に正規化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    resized = mx.image.resize_short(image, SIZE[0]).astype('float32')\n",
    "    cropped, crop_info = mx.image.center_crop(resized, SIZE)\n",
    "    cropped /= 255.\n",
    "    normalized = mx.image.color_normalize(cropped,\n",
    "                                      mean=MEAN_IMAGE,\n",
    "                                      std=STD_IMAGE) \n",
    "    transposed = nd.transpose(normalized, (2,0,1))\n",
    "    return transposed, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検索対象となる画像を展開します。[こちら](https://d1.awsstatic.com/Developer%20Marketing/jp/magazine/sample/data_elasticsearch-cat.2a73bad33290a2d7d909235c6a963f8fd3da691a.zip) の zip ファイルをダウンロード、解凍すると images.zip を取得できます。取得した images.zip をこのノートブックと同じ場所にアップロードしてから以降のセルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、猫の写真が入った images フォルダが作成されました。Jupyter のファイルブラウザをご確認ください。みなさまの猫の写真を追加する場合は、こちらの images フォルダに JPEG 画像を追加していただくと、みなさまの猫の写真が検索対象になります。写真を追加せずこのまま進めても構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folder = tempfile.mkdtemp()\n",
    "# Create an empty image Folder Data Set\n",
    "dataset = ImageFolderDataset(root=empty_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(os.path.join(image_path, '**.jpg') , recursive=True)\n",
    "print(\"[{}] images\".format(len(list_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.items = list(zip(list_files, [0]*len(list_files)))\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, last_batch='keep', shuffle=False, num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像から特徴ベクトルに変換\n",
    "機械学習モデルを使って画像を特徴ベクトルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((len(dataset), EMBEDDING_SIZE), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルの実行が完了するまでは t2.medium のインスタンスタイプで 20〜30秒ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tick = time.time()\n",
    "n_print = 100\n",
    "j = 0\n",
    "for i, (data, label) in enumerate(dataloader):\n",
    "    data = data.as_in_context(ctx)\n",
    "    if i%n_print == 0 and i > 0:\n",
    "        print(\"{0} batches, {1} images, {2:.3f} img/sec\".format(i, i*BATCH_SIZE, BATCH_SIZE*n_print/(time.time()-tick)))\n",
    "        tick = time.time()\n",
    "    output = net(data)\n",
    "    features[(i)*BATCH_SIZE:(i+1)*max(BATCH_SIZE, len(output)), :] = output.asnumpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Elasticsearch Service のセットアップ\n",
    "このサンプルでは、Amazon Elasticsearch Service (Amazon ES) を使って類似ベクトルを検索します。\n",
    "ここでは、Amazon ES を使うための設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch requests_aws4auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon ES インデックスの作成と特徴ベクトルの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import certifi\n",
    "from elasticsearch import Elasticsearch, helpers, RequestsHttpConnection\n",
    "from sklearn.preprocessing import normalize\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import elasticsearch\n",
    "import boto3\n",
    "\n",
    "dim = EMBEDDING_SIZE\n",
    "fvecs = features\n",
    "\n",
    "np.shape(fvecs)\n",
    "\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "\n",
    "idx_name = 'vsearch'\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts = [{'host': es_host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "\n",
    "res = es.cluster.put_settings({'persistent': {'knn.algo_param.index_thread_qty': 2}})\n",
    "print(res)\n",
    "\n",
    "mapping = {\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"knn\": True,\n",
    "            \"knn.algo_param\" : {\n",
    "                \"ef_search\" : \"256\",\n",
    "                \"ef_construction\" : \"128\",\n",
    "                \"m\" : \"48\"\n",
    "            },\n",
    "            'refresh_interval': -1,\n",
    "            'translog.flush_threshold_size': '10gb',\n",
    "            'number_of_replicas': 0\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'fvec': {\n",
    "                'type': 'knn_vector',\n",
    "                'dimension': dim\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.indices.create(index=idx_name, body=mapping, ignore=400)\n",
    "print(res)\n",
    "\n",
    "bs = 100\n",
    "nloop = math.ceil(fvecs.shape[0] / bs)\n",
    "\n",
    "for k in range(nloop):\n",
    "    rows = [{'_index': idx_name, '_id': f'{i}',\n",
    "             '_source': {'fvec': normalize(fvecs[i:i+1])[0].tolist()}}\n",
    "             for i in range(k * bs, min((k + 1) * bs, fvecs.shape[0]))]\n",
    "    s = time.time()\n",
    "    helpers.bulk(es, rows, request_timeout=30)\n",
    "#     print(k, time.time() - s)\n",
    "    \n",
    "res = es.indices.refresh(index=idx_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インデックス一覧を表示して、インデックスが作成されたか確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.cat.indices(v=True)\n",
    "item_num=es.count(index=idx_name)['count']\n",
    "print(res)\n",
    "print('number of images:', item_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ご参考] インデックスに新しい特徴ベクトルを追加する場合はコメントアウトを外して以下のコードを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'xxx.jpg'\n",
    "# image = plt.imread(image_path)[:,:,:3]\n",
    "# image_t, _ = transform(nd.array(image), 1) # モデルに合わせて画像サイズを変換\n",
    "# output = net(image_t.expand_dims(axis=0).as_in_context(ctx)) # 画像の特徴ベクトルを取得\n",
    "# item_num=es.count(index=idx_name)['count']\n",
    "# body={'fvec': normalize(output.asnumpy())[0].tolist()}\n",
    "# es.index(idx_name, body=body, id=item_num)\n",
    "# res = es.indices.refresh(index=idx_name)\n",
    "# item_num=es.count(index=idx_name)['count']\n",
    "\n",
    "# # dataset 更新\n",
    "# dataset.items.append((image_path, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ご参考] ID を指定してインデックスからアイテム（ドキュメント）を削除する場合はコメントアウトを外して以下のコードを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  任意の ID を持つドキュメントがあるか確認（以下の例では id=4）\n",
    "# del_id = 4\n",
    "# es.get(index=idx_name,id=del_id)\n",
    "# es.delete(index=idx_name, id=del_id)\n",
    "# res = es.indices.refresh(index=idx_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の検索\n",
    "ここでは、作成した Amazon ES を使った類似画像検索を行います。まずは検索および検索結果表示のための関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image(feature, num):\n",
    "    start = time.time()\n",
    "    res = es.search(request_timeout=300, index=idx_name,\n",
    "                    body={'size': num, '_source': False,\n",
    "                          'query': {'knn': {'fvec': {'vector': normalize(feature)[0].tolist(), 'k': num}}}})\n",
    "    print('time for query: ', str((time.time()-start)*1000), 'msec')\n",
    "#     print(json.dumps(res, indent=2))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(images, scores):\n",
    "    rows = len(images)//3+2\n",
    "    gs = gridspec.GridSpec(rows, 3)\n",
    "    fig = plt.figure(figsize=(15, 6*rows))\n",
    "    gs.update(hspace=0.1, wspace=0.1)\n",
    "    for i, (gg, image) in enumerate(zip(gs, images)):\n",
    "        gg2 = gridspec.GridSpecFromSubplotSpec(10, 10, subplot_spec=gg)\n",
    "        ax = fig.add_subplot(gg2[:,:])\n",
    "        ax.imshow(image, cmap='Greys_r')\n",
    "        ax.tick_params(axis='both',       \n",
    "                       which='both',      \n",
    "                       bottom='off',      \n",
    "                       top='off',         \n",
    "                       left='off',\n",
    "                       right='off',\n",
    "                       labelleft='off',\n",
    "                       labelbottom='off') \n",
    "        ax.axes.set_title(\"result [{}] score:{}\".format(i, scores[i-1]))\n",
    "        if i == 0:\n",
    "            plt.setp(ax.spines.values(), color='red')\n",
    "            ax.axes.set_title(\"SEARCH\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムに画像を選んで画像検索\n",
    "サンプルデータセットの中からランダムに一枚ピックアップして、その画像と似ている画像を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0,item_num)\n",
    "print('image index:', index)\n",
    "res = search_image(fvecs[index:index+1], 10)\n",
    "\n",
    "idx = []\n",
    "scores = []\n",
    "for i in res['hits']['hits']:\n",
    "    idx.append(int(i['_id']))\n",
    "    scores.append(i['_score'])\n",
    "    \n",
    "    \n",
    "# images = [plt.imread(dataset.items[index][0])]\n",
    "images=[]\n",
    "images += [plt.imread(dataset.items[label][0]) for label in idx[:]]\n",
    "plot_predictions(images, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任意の画像と似ている画像を検索\n",
    "ノートブックインスタンスに画像をアップロードし、その画像に似た画像を検索してみましょう。`testimg`に検索のキーとなる画像のパスを記載してから以下のセルを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg = '<file_path>' #  ./images/input.jpg のように画像を指定\n",
    "image = plt.imread(testimg)[:,:,:3]\n",
    "image_t, _ = transform(nd.array(image), 1) # モデルに合わせて画像サイズを変換\n",
    "output = net(image_t.expand_dims(axis=0).as_in_context(ctx)) # 画像の特徴ベクトルを取得\n",
    "res = search_image(output.asnumpy(), 10)\n",
    "\n",
    "idx = []\n",
    "scores = []\n",
    "for i in res['hits']['hits']:\n",
    "    idx.append(int(i['_id']))\n",
    "    scores.append(i['_score'])\n",
    "    \n",
    "images = [image]\n",
    "images += [plt.imread(dataset.items[label][0]) for label in idx[:]]\n",
    "plot_predictions(images, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リソースの削除\n",
    "[こちらの記事](https://aws.amazon.com/jp/builders-flash/202102/elasticsearch-your-cat/) の「リソースの削除」の部分を参考に、今回のハンズオンで作成したリソースを削除して課金を停止しましょう。この手順を忘れると課金が発生し続けますのでご注意ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "このノートブックでは、機械学習と Amazon ES を使った類似画像検索の方法をご紹介しました。今回は MXNet Gluon の学習済みモデルの中間出力を特徴ベクトルとして Amazon ES に登録し、K-NN を使って類似する特徴ベクトルを検索するアプローチを採りました。検索精度をあげる場合は、写真の撮影条件（明るさ、被写体の大きさ、ホワイトバランスなど）を揃える、特徴ベクトルを作成する部分のアルゴリズムを変更する、特徴ベクトルの次元を増やすなどの方法が考えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
